{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbd89436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras,os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "372eefb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "382c1497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_set', 'training_set']\n",
      "['beaches', 'bus', 'dinosaurs', 'elephants', 'flowers', 'foods', 'horses', 'monuments', 'mountains_and_snow', 'peolpe_and_villages_in_Africa']\n",
      "['beaches', 'bus', 'dinosaurs', 'elephants', 'flowers', 'foods', 'horses', 'monuments', 'mountains_and_snow', 'peolpe_and_villages_in_Africa']\n"
     ]
    }
   ],
   "source": [
    "os.mkdir('C:\\\\Users\\\\Dear\\\\Desktop\\\\FYP\\\\Testcode3-HOG\\\\HOG-master\\\\hog2_features_numpy')\n",
    "os.mkdir('C:\\\\Users\\\\Dear\\\\Desktop\\\\FYP\\\\Testcode3-HOG\\\\HOG-master\\\\hog2_features_numpy\\\\training_set')\n",
    "os.mkdir('C:\\\\Users\\\\Dear\\\\Desktop\\\\FYP\\\\Testcode3-HOG\\\\HOG-master\\\\hog2_features_numpy\\\\test_set')\n",
    "\n",
    "my_data_dir = 'C:\\\\Users\\\\Dear\\\\Desktop\\\\FYP\\\\Testcode3-HOG\\\\HOG-master\\\\resized_dataset'\n",
    "train_path = my_data_dir+'\\\\training_set\\\\'\n",
    "directories = os.listdir(train_path)\n",
    "\n",
    "#create folder for each class in the hog_features_numpy folder inside the train/test folder.\n",
    "    \n",
    "train_dir_hog='C:\\\\Users\\\\Dear\\\\Desktop\\\\FYP\\\\Testcode3-HOG\\\\HOG-master\\\\hog2_features_numpy\\\\training_set'\n",
    "test_dir_hog='C:\\\\Users\\\\Dear\\\\Desktop\\\\FYP\\\\Testcode3-HOG\\\\HOG-master\\\\hog2_features_numpy\\\\test_set'\n",
    "\n",
    "for item in directories:\n",
    "    path_train=os.path.join(train_dir_hog,item)\n",
    "    os.mkdir(path_train)\n",
    "    \n",
    "    path_test=os.path.join(test_dir_hog,item)\n",
    "    os.mkdir(path_test)\n",
    "    \n",
    "print(os.listdir('C:\\\\Users\\\\Dear\\Desktop\\FYP\\\\Testcode3-HOG\\\\HOG-master\\\\hog2_features_numpy'))\n",
    "print(os.listdir('C:\\\\Users\\\\Dear\\\\Desktop\\\\FYP\\\\Testcode3-HOG\\\\HOG-master\\\\hog2_features_numpy\\\\training_set'))\n",
    "print(os.listdir('C:\\\\Users\\\\Dear\\\\Desktop\\\\FYP\\\\Testcode3-HOG\\\\HOG-master\\\\hog2_features_numpy\\\\test_set'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "193162d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path='C:\\\\Users\\\\Dear\\\\Desktop\\\\FYP\\\\Testcode3-HOG\\\\HOG-master\\\\hog2_features\\\\features_train\\\\'\n",
    "output_path='C:\\\\Users\\\\Dear\\\\Desktop\\\\FYP\\\\Testcode3-HOG\\\\HOG-master\\\\hog2_features_numpy\\\\training_set\\\\'\n",
    "\n",
    "for item in directories: \n",
    "    Temp = training_path + item    \n",
    "    i=0\n",
    "    for filename in os.listdir(Temp):\n",
    "        text = np.loadtxt(os.path.join(Temp,filename))\n",
    "        path=os.path.join(output_path,item)\n",
    "        path=os.path.join(path,filename[:-4])\n",
    "        np.save(path,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4618fc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path='C:\\\\Users\\\\Dear\\\\Desktop\\\\FYP\\\\Testcode3-HOG\\\\HOG-master\\\\hog2_features\\\\features_test\\\\'\n",
    "output_path='C:\\\\Users\\\\Dear\\\\Desktop\\\\FYP\\\\Testcode3-HOG\\\\HOG-master\\\\hog2_features_numpy\\\\test_set\\\\'\n",
    "\n",
    "for item in directories: \n",
    "    Temp = test_path + item    \n",
    "    i=0\n",
    "    for filename in os.listdir(Temp):\n",
    "        text = np.loadtxt(os.path.join(Temp,filename))\n",
    "        path=os.path.join(output_path,item)\n",
    "        path=os.path.join(path,filename[:-4])\n",
    "        np.save(path,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "058474fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "traingenerator =  ImageDataGenerator()\n",
    "testgenerator = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bc63d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 10 classes.\n",
      "Found 0 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train = traingenerator.flow_from_directory(directory=\"C:\\\\Users\\\\Dear\\\\Desktop\\\\FYP\\\\Testcode3-HOG\\\\HOG-master\\\\hog2_features_numpy\\\\training_set\",\n",
    "                                                                 target_size=(14880,),\n",
    "                                                                class_mode='categorical',\n",
    "                                                                batch_size=16)\n",
    "x_test = testgenerator.flow_from_directory(directory=\"C:\\\\Users\\\\Dear\\\\Desktop\\\\FYP\\\\Testcode3-HOG\\\\HOG-master\\\\hog2_features_numpy\\\\test_set\",\n",
    "                                                                target_size=(14880,),\n",
    "                                                               class_mode='categorical',\n",
    "                                                               batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8966907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "953670c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_set', 'training_set']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = 'C:\\\\Users\\\\Dear\\\\Desktop\\\\FYP\\\\Testcode3-HOG\\\\HOG-master\\\\hog2_features_numpy\\\\'\n",
    "os.listdir(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebf7fac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f33b84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(v):\n",
    "    norm = np.linalg.norm(v)\n",
    "    if norm == 0: \n",
    "        return v\n",
    "    return v / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2adabdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(dir,os.listdir(dir)[1])\n",
    "\n",
    "for i, j in enumerate(os.listdir(train_path)):\n",
    "    class_path = os.path.join(train_path,j)\n",
    "    for arr in os.listdir(class_path):\n",
    "        nparr=np.load(os.path.join(class_path,arr))\n",
    "        x_train.append(normalize(nparr))\n",
    "        y_train.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f830008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efaea3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03706cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4755f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = os.path.join(dir,os.listdir(dir)[0])\n",
    "\n",
    "for i, j in enumerate(os.listdir(test_path)):\n",
    "    class_path = os.path.join(test_path,j)\n",
    "    for arr in os.listdir(class_path):\n",
    "        nparr=np.load(os.path.join(class_path,arr))\n",
    "        x_test.append(normalize(nparr))\n",
    "        y_test.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59506070",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b82e4977",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30006263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "y_train = tf.keras.utils.to_categorical(y_train,10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5556c5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1a461f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train= shuffle(x_train, y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b2592fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test= shuffle(x_test, y_test, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ba93485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 14880)\n",
      "(900, 10)\n",
      "(100, 14880)\n",
      "(100, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a754f9e5",
   "metadata": {},
   "source": [
    "# Training the neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f52bab6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the keras model - layer by layer\n",
    "kerasmodel= Sequential() #initializing model - Dense for fully connected layer\n",
    "kerasmodel.add(Dense(14880, activation='relu'))\n",
    "kerasmodel.add(Dropout(0.2))\n",
    "kerasmodel.add(Dense(7000, activation='relu'))\n",
    "kerasmodel.add(Dropout(0.3))\n",
    "kerasmodel.add(Dense(1000, activation='relu'))\n",
    "kerasmodel.add(Dropout(0.3))\n",
    "kerasmodel.add(Dense(64, activation='relu'))\n",
    "kerasmodel.add(Dropout(0.5))\n",
    "kerasmodel.add(Dense(32, activation='relu'))\n",
    "kerasmodel.add(Dropout(0.5))\n",
    "kerasmodel.add(Dense(10, activation= 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9e71335",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling model \n",
    "kerasmodel.compile(loss='categorical_crossentropy', optimizer= 'sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d207176b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "90/90 [==============================] - 469s 4s/step - loss: 2.3024 - accuracy: 0.1040 - val_loss: 2.3018 - val_accuracy: 0.0900\n",
      "Epoch 2/10\n",
      "90/90 [==============================] - 264s 3s/step - loss: 2.3019 - accuracy: 0.0953 - val_loss: 2.3002 - val_accuracy: 0.1400\n",
      "Epoch 3/10\n",
      "90/90 [==============================] - 262s 3s/step - loss: 2.3019 - accuracy: 0.1142 - val_loss: 2.2998 - val_accuracy: 0.1000\n",
      "Epoch 4/10\n",
      "90/90 [==============================] - 260s 3s/step - loss: 2.2986 - accuracy: 0.1153 - val_loss: 2.2974 - val_accuracy: 0.1400\n",
      "Epoch 5/10\n",
      "90/90 [==============================] - 268s 3s/step - loss: 2.2998 - accuracy: 0.1244 - val_loss: 2.2961 - val_accuracy: 0.2000\n",
      "Epoch 6/10\n",
      "88/90 [============================>.] - ETA: 6s - loss: 2.2989 - accuracy: 0.0860"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#fitting model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mkerasmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\dear\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\engine\\training.py:1158\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1152\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1153\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1154\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1155\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1156\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1157\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1158\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1159\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1160\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\users\\dear\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:889\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    888\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 889\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    891\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    892\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\users\\dear\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    914\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    915\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 917\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    920\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    921\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\users\\dear\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3023\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3020\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   3021\u001b[0m   (graph_function,\n\u001b[0;32m   3022\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\dear\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1960\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1956\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1958\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1959\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1960\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1961\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1962\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1963\u001b[0m     args,\n\u001b[0;32m   1964\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1965\u001b[0m     executing_eagerly)\n\u001b[0;32m   1966\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\users\\dear\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    597\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\users\\dear\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#fitting model\n",
    "kerasmodel.fit(x_train, y_train,validation_data=(x_test,y_test), epochs=10, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55ba712",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=kerasmodel.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b091d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "34c3915a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 5, 7, 4, 4, 3, 2, 8, 1, 0, 1, 3, 7, 3, 9, 0, 7, 7, 1, 3, 5, 8,\n",
       "       2, 4, 6, 1, 4, 9, 0, 7, 1, 4, 8, 2, 9, 0, 6, 6, 3, 1, 4, 3, 0, 9,\n",
       "       2, 1, 8, 2, 6, 1, 2, 0, 1, 3, 0, 7, 0, 6, 3, 8, 5, 9, 5, 4, 5, 6,\n",
       "       4, 6, 6, 9, 7, 4, 5, 4, 9, 5, 7, 3, 9, 5, 6, 8, 3, 2, 0, 5, 2, 0,\n",
       "       2, 8, 9, 7, 8, 8, 2, 6, 7, 1, 9, 5], dtype=int64)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testttt=np.argmax(y_test,axis=-1)\n",
    "testttt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b54f2626",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_enc = tf.keras.utils.to_categorical(y_pred,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5178a51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.30      0.30        10\n",
      "           1       0.50      0.90      0.64        10\n",
      "           2       0.90      0.90      0.90        10\n",
      "           3       0.33      0.70      0.45        10\n",
      "           4       0.53      0.90      0.67        10\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.50      0.20      0.29        10\n",
      "           7       0.33      0.10      0.15        10\n",
      "           8       0.50      0.30      0.37        10\n",
      "           9       0.30      0.30      0.30        10\n",
      "\n",
      "   micro avg       0.46      0.46      0.46       100\n",
      "   macro avg       0.42      0.46      0.41       100\n",
      "weighted avg       0.42      0.46      0.41       100\n",
      " samples avg       0.46      0.46      0.46       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sklearn\n",
    "\n",
    "print(sklearn.metrics.classification_report(y_test,y_pred_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3eac31cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step - loss: 2.0378 - accuracy: 0.5100\n"
     ]
    }
   ],
   "source": [
    "#train accuracy\n",
    "accuracy = kerasmodel.evaluate(x_train, y_train)\n",
    "#print('Train Accuracy: %.2f' %(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d122b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyexpat import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "09c3e387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4b74ae51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test accuracy \n",
    "y_pred = (kerasmodel.predict(x_test) > 0.5).astype(\"int32\")\n",
    "y_pred\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26c5536",
   "metadata": {},
   "source": [
    "## Model 1: VGGNet 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4cca5f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Conv2D(input_shape=(32,32,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model1.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model1.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model1.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model1.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model1.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model1.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model1.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model1.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model1.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model1.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model1.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model1.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model1.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model1.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model1.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model1.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model1.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ae6505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.add(Flatten())\n",
    "model1.add(Dense(units=4096,activation=\"relu\"))\n",
    "model1.add(Dense(units=4096,activation=\"relu\"))\n",
    "model1.add(Dense(units=10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd3acae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "opt = Adam(lr=0.001)\n",
    "model1.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "924c02f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (None, 32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87e93679",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.build(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aad9dafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 33,638,218\n",
      "Trainable params: 33,638,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cc5a94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\engine\\training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "29/29 [==============================] - 31s 1s/step - loss: 9.7596 - accuracy: 0.0967 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 30s 1s/step - loss: 2.3039 - accuracy: 0.0811 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 32s 1s/step - loss: 2.3033 - accuracy: 0.1022 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 33s 1s/step - loss: 2.3032 - accuracy: 0.0900 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 33s 1s/step - loss: 2.3034 - accuracy: 0.1000 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 36s 1s/step - loss: 2.3030 - accuracy: 0.1000 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 32s 1s/step - loss: 2.3030 - accuracy: 0.0933 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 34s 1s/step - loss: 2.3031 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 33s 1s/step - loss: 2.3029 - accuracy: 0.0933 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 30s 1s/step - loss: 2.3030 - accuracy: 0.1000 - val_loss: 2.3027 - val_accuracy: 0.1000\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "#checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "hist = model1.fit_generator(x_train,y_train, validation_data=(x_test,y_test), validation_steps=4,epochs=10,callbacks=[early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25dd5d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.image  as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "#-----------------------------------------------------------\n",
    "acc=hist.history['accuracy']\n",
    "val_acc=hist.history['val_accuracy']\n",
    "loss=hist.history['loss']\n",
    "val_loss=hist.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc)) # Get number of epochs\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation accuracy per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.figure()\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation loss per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "# Desired output. Charts with training and validation metrics. No crash :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a194a1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 5s 156ms/step - loss: 2.3027 - accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.3026888370513916, 0.10000000149011612]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b66bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
